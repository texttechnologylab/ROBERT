# CMAKE generated file: DO NOT EDIT!
# Generated by "MinGW Makefiles" Generator, CMake Version 3.26

# Default target executed when no arguments are given to make.
default_target: all
.PHONY : default_target

#=============================================================================
# Special targets provided by cmake.

# Disable implicit rules so canonical targets will work.
.SUFFIXES:

# Disable VCS-based implicit rules.
% : %,v

# Disable VCS-based implicit rules.
% : RCS/%

# Disable VCS-based implicit rules.
% : RCS/%,v

# Disable VCS-based implicit rules.
% : SCCS/s.%

# Disable VCS-based implicit rules.
% : s.%

.SUFFIXES: .hpux_make_needs_suffix_list

# Produce verbose output by default.
VERBOSE = 1

# Command-line flag to silence nested $(MAKE).
$(VERBOSE)MAKESILENT = -s

#Suppress display of executed commands.
$(VERBOSE).SILENT:

# A target that is always out of date.
cmake_force:
.PHONY : cmake_force

#=============================================================================
# Set environment variables for the build.

SHELL = cmd.exe

# The CMake executable.
CMAKE_COMMAND = C:\tools\mingw64\bin\cmake.exe

# The command to remove a file.
RM = C:\tools\mingw64\bin\cmake.exe -E rm -f

# Escaping for special characters.
EQUALS = =

# The top-level source directory on which CMake was run.
CMAKE_SOURCE_DIR = "E:\Python Projects\R.O.B.E.R.T\source\R.O.B.E.R.T\src\training\gpt4all\gpt4all-backend"

# The top-level build directory on which CMake was run.
CMAKE_BINARY_DIR = "E:\Python Projects\R.O.B.E.R.T\source\R.O.B.E.R.T\src\training\gpt4all\gpt4all-backend\build"

#=============================================================================
# Directory level rules for the build root directory

# The main recursive "all" target.
all: CMakeFiles/llmodel.dir/all
all: llama.cpp/all
.PHONY : all

# The main recursive "preinstall" target.
preinstall: llama.cpp/preinstall
.PHONY : preinstall

# The main recursive "clean" target.
clean: CMakeFiles/llmodel.dir/clean
clean: llama.cpp/clean
.PHONY : clean

#=============================================================================
# Directory level rules for directory llama.cpp

# Recursive "all" directory target.
llama.cpp/all: llama.cpp/CMakeFiles/ggml.dir/all
llama.cpp/all: llama.cpp/CMakeFiles/llama.dir/all
llama.cpp/all: llama.cpp/examples/all
llama.cpp/all: llama.cpp/pocs/all
.PHONY : llama.cpp/all

# Recursive "preinstall" directory target.
llama.cpp/preinstall: llama.cpp/examples/preinstall
llama.cpp/preinstall: llama.cpp/pocs/preinstall
.PHONY : llama.cpp/preinstall

# Recursive "clean" directory target.
llama.cpp/clean: llama.cpp/CMakeFiles/ggml.dir/clean
llama.cpp/clean: llama.cpp/CMakeFiles/llama.dir/clean
llama.cpp/clean: llama.cpp/examples/clean
llama.cpp/clean: llama.cpp/pocs/clean
.PHONY : llama.cpp/clean

#=============================================================================
# Directory level rules for directory llama.cpp/examples

# Recursive "all" directory target.
llama.cpp/examples/all: llama.cpp/examples/CMakeFiles/common.dir/all
llama.cpp/examples/all: llama.cpp/examples/main/all
llama.cpp/examples/all: llama.cpp/examples/quantize/all
llama.cpp/examples/all: llama.cpp/examples/quantize-stats/all
llama.cpp/examples/all: llama.cpp/examples/perplexity/all
llama.cpp/examples/all: llama.cpp/examples/embedding/all
llama.cpp/examples/all: llama.cpp/examples/save-load-state/all
.PHONY : llama.cpp/examples/all

# Recursive "preinstall" directory target.
llama.cpp/examples/preinstall: llama.cpp/examples/main/preinstall
llama.cpp/examples/preinstall: llama.cpp/examples/quantize/preinstall
llama.cpp/examples/preinstall: llama.cpp/examples/quantize-stats/preinstall
llama.cpp/examples/preinstall: llama.cpp/examples/perplexity/preinstall
llama.cpp/examples/preinstall: llama.cpp/examples/embedding/preinstall
llama.cpp/examples/preinstall: llama.cpp/examples/save-load-state/preinstall
.PHONY : llama.cpp/examples/preinstall

# Recursive "clean" directory target.
llama.cpp/examples/clean: llama.cpp/examples/CMakeFiles/common.dir/clean
llama.cpp/examples/clean: llama.cpp/examples/main/clean
llama.cpp/examples/clean: llama.cpp/examples/quantize/clean
llama.cpp/examples/clean: llama.cpp/examples/quantize-stats/clean
llama.cpp/examples/clean: llama.cpp/examples/perplexity/clean
llama.cpp/examples/clean: llama.cpp/examples/embedding/clean
llama.cpp/examples/clean: llama.cpp/examples/save-load-state/clean
.PHONY : llama.cpp/examples/clean

#=============================================================================
# Directory level rules for directory llama.cpp/examples/embedding

# Recursive "all" directory target.
llama.cpp/examples/embedding/all: llama.cpp/examples/embedding/CMakeFiles/embedding.dir/all
.PHONY : llama.cpp/examples/embedding/all

# Recursive "preinstall" directory target.
llama.cpp/examples/embedding/preinstall:
.PHONY : llama.cpp/examples/embedding/preinstall

# Recursive "clean" directory target.
llama.cpp/examples/embedding/clean: llama.cpp/examples/embedding/CMakeFiles/embedding.dir/clean
.PHONY : llama.cpp/examples/embedding/clean

#=============================================================================
# Directory level rules for directory llama.cpp/examples/main

# Recursive "all" directory target.
llama.cpp/examples/main/all: llama.cpp/examples/main/CMakeFiles/main.dir/all
.PHONY : llama.cpp/examples/main/all

# Recursive "preinstall" directory target.
llama.cpp/examples/main/preinstall:
.PHONY : llama.cpp/examples/main/preinstall

# Recursive "clean" directory target.
llama.cpp/examples/main/clean: llama.cpp/examples/main/CMakeFiles/main.dir/clean
.PHONY : llama.cpp/examples/main/clean

#=============================================================================
# Directory level rules for directory llama.cpp/examples/perplexity

# Recursive "all" directory target.
llama.cpp/examples/perplexity/all: llama.cpp/examples/perplexity/CMakeFiles/perplexity.dir/all
.PHONY : llama.cpp/examples/perplexity/all

# Recursive "preinstall" directory target.
llama.cpp/examples/perplexity/preinstall:
.PHONY : llama.cpp/examples/perplexity/preinstall

# Recursive "clean" directory target.
llama.cpp/examples/perplexity/clean: llama.cpp/examples/perplexity/CMakeFiles/perplexity.dir/clean
.PHONY : llama.cpp/examples/perplexity/clean

#=============================================================================
# Directory level rules for directory llama.cpp/examples/quantize

# Recursive "all" directory target.
llama.cpp/examples/quantize/all: llama.cpp/examples/quantize/CMakeFiles/quantize.dir/all
.PHONY : llama.cpp/examples/quantize/all

# Recursive "preinstall" directory target.
llama.cpp/examples/quantize/preinstall:
.PHONY : llama.cpp/examples/quantize/preinstall

# Recursive "clean" directory target.
llama.cpp/examples/quantize/clean: llama.cpp/examples/quantize/CMakeFiles/quantize.dir/clean
.PHONY : llama.cpp/examples/quantize/clean

#=============================================================================
# Directory level rules for directory llama.cpp/examples/quantize-stats

# Recursive "all" directory target.
llama.cpp/examples/quantize-stats/all: llama.cpp/examples/quantize-stats/CMakeFiles/quantize-stats.dir/all
.PHONY : llama.cpp/examples/quantize-stats/all

# Recursive "preinstall" directory target.
llama.cpp/examples/quantize-stats/preinstall:
.PHONY : llama.cpp/examples/quantize-stats/preinstall

# Recursive "clean" directory target.
llama.cpp/examples/quantize-stats/clean: llama.cpp/examples/quantize-stats/CMakeFiles/quantize-stats.dir/clean
.PHONY : llama.cpp/examples/quantize-stats/clean

#=============================================================================
# Directory level rules for directory llama.cpp/examples/save-load-state

# Recursive "all" directory target.
llama.cpp/examples/save-load-state/all: llama.cpp/examples/save-load-state/CMakeFiles/save-load-state.dir/all
.PHONY : llama.cpp/examples/save-load-state/all

# Recursive "preinstall" directory target.
llama.cpp/examples/save-load-state/preinstall:
.PHONY : llama.cpp/examples/save-load-state/preinstall

# Recursive "clean" directory target.
llama.cpp/examples/save-load-state/clean: llama.cpp/examples/save-load-state/CMakeFiles/save-load-state.dir/clean
.PHONY : llama.cpp/examples/save-load-state/clean

#=============================================================================
# Directory level rules for directory llama.cpp/pocs

# Recursive "all" directory target.
llama.cpp/pocs/all: llama.cpp/pocs/vdot/all
.PHONY : llama.cpp/pocs/all

# Recursive "preinstall" directory target.
llama.cpp/pocs/preinstall: llama.cpp/pocs/vdot/preinstall
.PHONY : llama.cpp/pocs/preinstall

# Recursive "clean" directory target.
llama.cpp/pocs/clean: llama.cpp/pocs/vdot/clean
.PHONY : llama.cpp/pocs/clean

#=============================================================================
# Directory level rules for directory llama.cpp/pocs/vdot

# Recursive "all" directory target.
llama.cpp/pocs/vdot/all: llama.cpp/pocs/vdot/CMakeFiles/vdot.dir/all
llama.cpp/pocs/vdot/all: llama.cpp/pocs/vdot/CMakeFiles/q8dot.dir/all
.PHONY : llama.cpp/pocs/vdot/all

# Recursive "preinstall" directory target.
llama.cpp/pocs/vdot/preinstall:
.PHONY : llama.cpp/pocs/vdot/preinstall

# Recursive "clean" directory target.
llama.cpp/pocs/vdot/clean: llama.cpp/pocs/vdot/CMakeFiles/vdot.dir/clean
llama.cpp/pocs/vdot/clean: llama.cpp/pocs/vdot/CMakeFiles/q8dot.dir/clean
.PHONY : llama.cpp/pocs/vdot/clean

#=============================================================================
# Target rules for target CMakeFiles/llmodel.dir

# All Build rule for target.
CMakeFiles/llmodel.dir/all: llama.cpp/CMakeFiles/llama.dir/all
	$(MAKE) $(MAKESILENT) -f CMakeFiles\llmodel.dir\build.make CMakeFiles/llmodel.dir/depend
	$(MAKE) $(MAKESILENT) -f CMakeFiles\llmodel.dir\build.make CMakeFiles/llmodel.dir/build
	@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --progress-dir="E:\Python Projects\R.O.B.E.R.T\source\R.O.B.E.R.T\src\training\gpt4all\gpt4all-backend\build\CMakeFiles" --progress-num=7,8,9,10,11,12,13 "Built target llmodel"
.PHONY : CMakeFiles/llmodel.dir/all

# Build rule for subdir invocation for target.
CMakeFiles/llmodel.dir/rule: cmake_check_build_system
	$(CMAKE_COMMAND) -E cmake_progress_start "E:\Python Projects\R.O.B.E.R.T\source\R.O.B.E.R.T\src\training\gpt4all\gpt4all-backend\build\CMakeFiles" 10
	$(MAKE) $(MAKESILENT) -f CMakeFiles\Makefile2 CMakeFiles/llmodel.dir/all
	$(CMAKE_COMMAND) -E cmake_progress_start "E:\Python Projects\R.O.B.E.R.T\source\R.O.B.E.R.T\src\training\gpt4all\gpt4all-backend\build\CMakeFiles" 0
.PHONY : CMakeFiles/llmodel.dir/rule

# Convenience name for target.
llmodel: CMakeFiles/llmodel.dir/rule
.PHONY : llmodel

# clean rule for target.
CMakeFiles/llmodel.dir/clean:
	$(MAKE) $(MAKESILENT) -f CMakeFiles\llmodel.dir\build.make CMakeFiles/llmodel.dir/clean
.PHONY : CMakeFiles/llmodel.dir/clean

#=============================================================================
# Target rules for target llama.cpp/CMakeFiles/ggml.dir

# All Build rule for target.
llama.cpp/CMakeFiles/ggml.dir/all:
	$(MAKE) $(MAKESILENT) -f llama.cpp\CMakeFiles\ggml.dir\build.make llama.cpp/CMakeFiles/ggml.dir/depend
	$(MAKE) $(MAKESILENT) -f llama.cpp\CMakeFiles\ggml.dir\build.make llama.cpp/CMakeFiles/ggml.dir/build
	@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --progress-dir="E:\Python Projects\R.O.B.E.R.T\source\R.O.B.E.R.T\src\training\gpt4all\gpt4all-backend\build\CMakeFiles" --progress-num=4 "Built target ggml"
.PHONY : llama.cpp/CMakeFiles/ggml.dir/all

# Build rule for subdir invocation for target.
llama.cpp/CMakeFiles/ggml.dir/rule: cmake_check_build_system
	$(CMAKE_COMMAND) -E cmake_progress_start "E:\Python Projects\R.O.B.E.R.T\source\R.O.B.E.R.T\src\training\gpt4all\gpt4all-backend\build\CMakeFiles" 1
	$(MAKE) $(MAKESILENT) -f CMakeFiles\Makefile2 llama.cpp/CMakeFiles/ggml.dir/all
	$(CMAKE_COMMAND) -E cmake_progress_start "E:\Python Projects\R.O.B.E.R.T\source\R.O.B.E.R.T\src\training\gpt4all\gpt4all-backend\build\CMakeFiles" 0
.PHONY : llama.cpp/CMakeFiles/ggml.dir/rule

# Convenience name for target.
ggml: llama.cpp/CMakeFiles/ggml.dir/rule
.PHONY : ggml

# clean rule for target.
llama.cpp/CMakeFiles/ggml.dir/clean:
	$(MAKE) $(MAKESILENT) -f llama.cpp\CMakeFiles\ggml.dir\build.make llama.cpp/CMakeFiles/ggml.dir/clean
.PHONY : llama.cpp/CMakeFiles/ggml.dir/clean

#=============================================================================
# Target rules for target llama.cpp/CMakeFiles/llama.dir

# All Build rule for target.
llama.cpp/CMakeFiles/llama.dir/all: llama.cpp/CMakeFiles/ggml.dir/all
	$(MAKE) $(MAKESILENT) -f llama.cpp\CMakeFiles\llama.dir\build.make llama.cpp/CMakeFiles/llama.dir/depend
	$(MAKE) $(MAKESILENT) -f llama.cpp\CMakeFiles\llama.dir\build.make llama.cpp/CMakeFiles/llama.dir/build
	@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --progress-dir="E:\Python Projects\R.O.B.E.R.T\source\R.O.B.E.R.T\src\training\gpt4all\gpt4all-backend\build\CMakeFiles" --progress-num=5,6 "Built target llama"
.PHONY : llama.cpp/CMakeFiles/llama.dir/all

# Build rule for subdir invocation for target.
llama.cpp/CMakeFiles/llama.dir/rule: cmake_check_build_system
	$(CMAKE_COMMAND) -E cmake_progress_start "E:\Python Projects\R.O.B.E.R.T\source\R.O.B.E.R.T\src\training\gpt4all\gpt4all-backend\build\CMakeFiles" 3
	$(MAKE) $(MAKESILENT) -f CMakeFiles\Makefile2 llama.cpp/CMakeFiles/llama.dir/all
	$(CMAKE_COMMAND) -E cmake_progress_start "E:\Python Projects\R.O.B.E.R.T\source\R.O.B.E.R.T\src\training\gpt4all\gpt4all-backend\build\CMakeFiles" 0
.PHONY : llama.cpp/CMakeFiles/llama.dir/rule

# Convenience name for target.
llama: llama.cpp/CMakeFiles/llama.dir/rule
.PHONY : llama

# clean rule for target.
llama.cpp/CMakeFiles/llama.dir/clean:
	$(MAKE) $(MAKESILENT) -f llama.cpp\CMakeFiles\llama.dir\build.make llama.cpp/CMakeFiles/llama.dir/clean
.PHONY : llama.cpp/CMakeFiles/llama.dir/clean

#=============================================================================
# Target rules for target llama.cpp/examples/CMakeFiles/common.dir

# All Build rule for target.
llama.cpp/examples/CMakeFiles/common.dir/all: llama.cpp/CMakeFiles/llama.dir/all
	$(MAKE) $(MAKESILENT) -f llama.cpp\examples\CMakeFiles\common.dir\build.make llama.cpp/examples/CMakeFiles/common.dir/depend
	$(MAKE) $(MAKESILENT) -f llama.cpp\examples\CMakeFiles\common.dir\build.make llama.cpp/examples/CMakeFiles/common.dir/build
	@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --progress-dir="E:\Python Projects\R.O.B.E.R.T\source\R.O.B.E.R.T\src\training\gpt4all\gpt4all-backend\build\CMakeFiles" --progress-num=1 "Built target common"
.PHONY : llama.cpp/examples/CMakeFiles/common.dir/all

# Build rule for subdir invocation for target.
llama.cpp/examples/CMakeFiles/common.dir/rule: cmake_check_build_system
	$(CMAKE_COMMAND) -E cmake_progress_start "E:\Python Projects\R.O.B.E.R.T\source\R.O.B.E.R.T\src\training\gpt4all\gpt4all-backend\build\CMakeFiles" 4
	$(MAKE) $(MAKESILENT) -f CMakeFiles\Makefile2 llama.cpp/examples/CMakeFiles/common.dir/all
	$(CMAKE_COMMAND) -E cmake_progress_start "E:\Python Projects\R.O.B.E.R.T\source\R.O.B.E.R.T\src\training\gpt4all\gpt4all-backend\build\CMakeFiles" 0
.PHONY : llama.cpp/examples/CMakeFiles/common.dir/rule

# Convenience name for target.
common: llama.cpp/examples/CMakeFiles/common.dir/rule
.PHONY : common

# clean rule for target.
llama.cpp/examples/CMakeFiles/common.dir/clean:
	$(MAKE) $(MAKESILENT) -f llama.cpp\examples\CMakeFiles\common.dir\build.make llama.cpp/examples/CMakeFiles/common.dir/clean
.PHONY : llama.cpp/examples/CMakeFiles/common.dir/clean

#=============================================================================
# Target rules for target llama.cpp/examples/main/CMakeFiles/main.dir

# All Build rule for target.
llama.cpp/examples/main/CMakeFiles/main.dir/all: llama.cpp/CMakeFiles/llama.dir/all
llama.cpp/examples/main/CMakeFiles/main.dir/all: llama.cpp/examples/CMakeFiles/common.dir/all
	$(MAKE) $(MAKESILENT) -f llama.cpp\examples\main\CMakeFiles\main.dir\build.make llama.cpp/examples/main/CMakeFiles/main.dir/depend
	$(MAKE) $(MAKESILENT) -f llama.cpp\examples\main\CMakeFiles\main.dir\build.make llama.cpp/examples/main/CMakeFiles/main.dir/build
	@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --progress-dir="E:\Python Projects\R.O.B.E.R.T\source\R.O.B.E.R.T\src\training\gpt4all\gpt4all-backend\build\CMakeFiles" --progress-num=14,15 "Built target main"
.PHONY : llama.cpp/examples/main/CMakeFiles/main.dir/all

# Build rule for subdir invocation for target.
llama.cpp/examples/main/CMakeFiles/main.dir/rule: cmake_check_build_system
	$(CMAKE_COMMAND) -E cmake_progress_start "E:\Python Projects\R.O.B.E.R.T\source\R.O.B.E.R.T\src\training\gpt4all\gpt4all-backend\build\CMakeFiles" 6
	$(MAKE) $(MAKESILENT) -f CMakeFiles\Makefile2 llama.cpp/examples/main/CMakeFiles/main.dir/all
	$(CMAKE_COMMAND) -E cmake_progress_start "E:\Python Projects\R.O.B.E.R.T\source\R.O.B.E.R.T\src\training\gpt4all\gpt4all-backend\build\CMakeFiles" 0
.PHONY : llama.cpp/examples/main/CMakeFiles/main.dir/rule

# Convenience name for target.
main: llama.cpp/examples/main/CMakeFiles/main.dir/rule
.PHONY : main

# clean rule for target.
llama.cpp/examples/main/CMakeFiles/main.dir/clean:
	$(MAKE) $(MAKESILENT) -f llama.cpp\examples\main\CMakeFiles\main.dir\build.make llama.cpp/examples/main/CMakeFiles/main.dir/clean
.PHONY : llama.cpp/examples/main/CMakeFiles/main.dir/clean

#=============================================================================
# Target rules for target llama.cpp/examples/quantize/CMakeFiles/quantize.dir

# All Build rule for target.
llama.cpp/examples/quantize/CMakeFiles/quantize.dir/all: llama.cpp/CMakeFiles/llama.dir/all
	$(MAKE) $(MAKESILENT) -f llama.cpp\examples\quantize\CMakeFiles\quantize.dir\build.make llama.cpp/examples/quantize/CMakeFiles/quantize.dir/depend
	$(MAKE) $(MAKESILENT) -f llama.cpp\examples\quantize\CMakeFiles\quantize.dir\build.make llama.cpp/examples/quantize/CMakeFiles/quantize.dir/build
	@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --progress-dir="E:\Python Projects\R.O.B.E.R.T\source\R.O.B.E.R.T\src\training\gpt4all\gpt4all-backend\build\CMakeFiles" --progress-num=20,21 "Built target quantize"
.PHONY : llama.cpp/examples/quantize/CMakeFiles/quantize.dir/all

# Build rule for subdir invocation for target.
llama.cpp/examples/quantize/CMakeFiles/quantize.dir/rule: cmake_check_build_system
	$(CMAKE_COMMAND) -E cmake_progress_start "E:\Python Projects\R.O.B.E.R.T\source\R.O.B.E.R.T\src\training\gpt4all\gpt4all-backend\build\CMakeFiles" 5
	$(MAKE) $(MAKESILENT) -f CMakeFiles\Makefile2 llama.cpp/examples/quantize/CMakeFiles/quantize.dir/all
	$(CMAKE_COMMAND) -E cmake_progress_start "E:\Python Projects\R.O.B.E.R.T\source\R.O.B.E.R.T\src\training\gpt4all\gpt4all-backend\build\CMakeFiles" 0
.PHONY : llama.cpp/examples/quantize/CMakeFiles/quantize.dir/rule

# Convenience name for target.
quantize: llama.cpp/examples/quantize/CMakeFiles/quantize.dir/rule
.PHONY : quantize

# clean rule for target.
llama.cpp/examples/quantize/CMakeFiles/quantize.dir/clean:
	$(MAKE) $(MAKESILENT) -f llama.cpp\examples\quantize\CMakeFiles\quantize.dir\build.make llama.cpp/examples/quantize/CMakeFiles/quantize.dir/clean
.PHONY : llama.cpp/examples/quantize/CMakeFiles/quantize.dir/clean

#=============================================================================
# Target rules for target llama.cpp/examples/quantize-stats/CMakeFiles/quantize-stats.dir

# All Build rule for target.
llama.cpp/examples/quantize-stats/CMakeFiles/quantize-stats.dir/all: llama.cpp/CMakeFiles/llama.dir/all
	$(MAKE) $(MAKESILENT) -f llama.cpp\examples\quantize-stats\CMakeFiles\quantize-stats.dir\build.make llama.cpp/examples/quantize-stats/CMakeFiles/quantize-stats.dir/depend
	$(MAKE) $(MAKESILENT) -f llama.cpp\examples\quantize-stats\CMakeFiles\quantize-stats.dir\build.make llama.cpp/examples/quantize-stats/CMakeFiles/quantize-stats.dir/build
	@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --progress-dir="E:\Python Projects\R.O.B.E.R.T\source\R.O.B.E.R.T\src\training\gpt4all\gpt4all-backend\build\CMakeFiles" --progress-num=22,23 "Built target quantize-stats"
.PHONY : llama.cpp/examples/quantize-stats/CMakeFiles/quantize-stats.dir/all

# Build rule for subdir invocation for target.
llama.cpp/examples/quantize-stats/CMakeFiles/quantize-stats.dir/rule: cmake_check_build_system
	$(CMAKE_COMMAND) -E cmake_progress_start "E:\Python Projects\R.O.B.E.R.T\source\R.O.B.E.R.T\src\training\gpt4all\gpt4all-backend\build\CMakeFiles" 5
	$(MAKE) $(MAKESILENT) -f CMakeFiles\Makefile2 llama.cpp/examples/quantize-stats/CMakeFiles/quantize-stats.dir/all
	$(CMAKE_COMMAND) -E cmake_progress_start "E:\Python Projects\R.O.B.E.R.T\source\R.O.B.E.R.T\src\training\gpt4all\gpt4all-backend\build\CMakeFiles" 0
.PHONY : llama.cpp/examples/quantize-stats/CMakeFiles/quantize-stats.dir/rule

# Convenience name for target.
quantize-stats: llama.cpp/examples/quantize-stats/CMakeFiles/quantize-stats.dir/rule
.PHONY : quantize-stats

# clean rule for target.
llama.cpp/examples/quantize-stats/CMakeFiles/quantize-stats.dir/clean:
	$(MAKE) $(MAKESILENT) -f llama.cpp\examples\quantize-stats\CMakeFiles\quantize-stats.dir\build.make llama.cpp/examples/quantize-stats/CMakeFiles/quantize-stats.dir/clean
.PHONY : llama.cpp/examples/quantize-stats/CMakeFiles/quantize-stats.dir/clean

#=============================================================================
# Target rules for target llama.cpp/examples/perplexity/CMakeFiles/perplexity.dir

# All Build rule for target.
llama.cpp/examples/perplexity/CMakeFiles/perplexity.dir/all: llama.cpp/CMakeFiles/llama.dir/all
llama.cpp/examples/perplexity/CMakeFiles/perplexity.dir/all: llama.cpp/examples/CMakeFiles/common.dir/all
	$(MAKE) $(MAKESILENT) -f llama.cpp\examples\perplexity\CMakeFiles\perplexity.dir\build.make llama.cpp/examples/perplexity/CMakeFiles/perplexity.dir/depend
	$(MAKE) $(MAKESILENT) -f llama.cpp\examples\perplexity\CMakeFiles\perplexity.dir\build.make llama.cpp/examples/perplexity/CMakeFiles/perplexity.dir/build
	@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --progress-dir="E:\Python Projects\R.O.B.E.R.T\source\R.O.B.E.R.T\src\training\gpt4all\gpt4all-backend\build\CMakeFiles" --progress-num=16,17 "Built target perplexity"
.PHONY : llama.cpp/examples/perplexity/CMakeFiles/perplexity.dir/all

# Build rule for subdir invocation for target.
llama.cpp/examples/perplexity/CMakeFiles/perplexity.dir/rule: cmake_check_build_system
	$(CMAKE_COMMAND) -E cmake_progress_start "E:\Python Projects\R.O.B.E.R.T\source\R.O.B.E.R.T\src\training\gpt4all\gpt4all-backend\build\CMakeFiles" 6
	$(MAKE) $(MAKESILENT) -f CMakeFiles\Makefile2 llama.cpp/examples/perplexity/CMakeFiles/perplexity.dir/all
	$(CMAKE_COMMAND) -E cmake_progress_start "E:\Python Projects\R.O.B.E.R.T\source\R.O.B.E.R.T\src\training\gpt4all\gpt4all-backend\build\CMakeFiles" 0
.PHONY : llama.cpp/examples/perplexity/CMakeFiles/perplexity.dir/rule

# Convenience name for target.
perplexity: llama.cpp/examples/perplexity/CMakeFiles/perplexity.dir/rule
.PHONY : perplexity

# clean rule for target.
llama.cpp/examples/perplexity/CMakeFiles/perplexity.dir/clean:
	$(MAKE) $(MAKESILENT) -f llama.cpp\examples\perplexity\CMakeFiles\perplexity.dir\build.make llama.cpp/examples/perplexity/CMakeFiles/perplexity.dir/clean
.PHONY : llama.cpp/examples/perplexity/CMakeFiles/perplexity.dir/clean

#=============================================================================
# Target rules for target llama.cpp/examples/embedding/CMakeFiles/embedding.dir

# All Build rule for target.
llama.cpp/examples/embedding/CMakeFiles/embedding.dir/all: llama.cpp/CMakeFiles/llama.dir/all
llama.cpp/examples/embedding/CMakeFiles/embedding.dir/all: llama.cpp/examples/CMakeFiles/common.dir/all
	$(MAKE) $(MAKESILENT) -f llama.cpp\examples\embedding\CMakeFiles\embedding.dir\build.make llama.cpp/examples/embedding/CMakeFiles/embedding.dir/depend
	$(MAKE) $(MAKESILENT) -f llama.cpp\examples\embedding\CMakeFiles\embedding.dir\build.make llama.cpp/examples/embedding/CMakeFiles/embedding.dir/build
	@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --progress-dir="E:\Python Projects\R.O.B.E.R.T\source\R.O.B.E.R.T\src\training\gpt4all\gpt4all-backend\build\CMakeFiles" --progress-num=2,3 "Built target embedding"
.PHONY : llama.cpp/examples/embedding/CMakeFiles/embedding.dir/all

# Build rule for subdir invocation for target.
llama.cpp/examples/embedding/CMakeFiles/embedding.dir/rule: cmake_check_build_system
	$(CMAKE_COMMAND) -E cmake_progress_start "E:\Python Projects\R.O.B.E.R.T\source\R.O.B.E.R.T\src\training\gpt4all\gpt4all-backend\build\CMakeFiles" 6
	$(MAKE) $(MAKESILENT) -f CMakeFiles\Makefile2 llama.cpp/examples/embedding/CMakeFiles/embedding.dir/all
	$(CMAKE_COMMAND) -E cmake_progress_start "E:\Python Projects\R.O.B.E.R.T\source\R.O.B.E.R.T\src\training\gpt4all\gpt4all-backend\build\CMakeFiles" 0
.PHONY : llama.cpp/examples/embedding/CMakeFiles/embedding.dir/rule

# Convenience name for target.
embedding: llama.cpp/examples/embedding/CMakeFiles/embedding.dir/rule
.PHONY : embedding

# clean rule for target.
llama.cpp/examples/embedding/CMakeFiles/embedding.dir/clean:
	$(MAKE) $(MAKESILENT) -f llama.cpp\examples\embedding\CMakeFiles\embedding.dir\build.make llama.cpp/examples/embedding/CMakeFiles/embedding.dir/clean
.PHONY : llama.cpp/examples/embedding/CMakeFiles/embedding.dir/clean

#=============================================================================
# Target rules for target llama.cpp/examples/save-load-state/CMakeFiles/save-load-state.dir

# All Build rule for target.
llama.cpp/examples/save-load-state/CMakeFiles/save-load-state.dir/all: llama.cpp/CMakeFiles/llama.dir/all
llama.cpp/examples/save-load-state/CMakeFiles/save-load-state.dir/all: llama.cpp/examples/CMakeFiles/common.dir/all
	$(MAKE) $(MAKESILENT) -f llama.cpp\examples\save-load-state\CMakeFiles\save-load-state.dir\build.make llama.cpp/examples/save-load-state/CMakeFiles/save-load-state.dir/depend
	$(MAKE) $(MAKESILENT) -f llama.cpp\examples\save-load-state\CMakeFiles\save-load-state.dir\build.make llama.cpp/examples/save-load-state/CMakeFiles/save-load-state.dir/build
	@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --progress-dir="E:\Python Projects\R.O.B.E.R.T\source\R.O.B.E.R.T\src\training\gpt4all\gpt4all-backend\build\CMakeFiles" --progress-num=24,25 "Built target save-load-state"
.PHONY : llama.cpp/examples/save-load-state/CMakeFiles/save-load-state.dir/all

# Build rule for subdir invocation for target.
llama.cpp/examples/save-load-state/CMakeFiles/save-load-state.dir/rule: cmake_check_build_system
	$(CMAKE_COMMAND) -E cmake_progress_start "E:\Python Projects\R.O.B.E.R.T\source\R.O.B.E.R.T\src\training\gpt4all\gpt4all-backend\build\CMakeFiles" 6
	$(MAKE) $(MAKESILENT) -f CMakeFiles\Makefile2 llama.cpp/examples/save-load-state/CMakeFiles/save-load-state.dir/all
	$(CMAKE_COMMAND) -E cmake_progress_start "E:\Python Projects\R.O.B.E.R.T\source\R.O.B.E.R.T\src\training\gpt4all\gpt4all-backend\build\CMakeFiles" 0
.PHONY : llama.cpp/examples/save-load-state/CMakeFiles/save-load-state.dir/rule

# Convenience name for target.
save-load-state: llama.cpp/examples/save-load-state/CMakeFiles/save-load-state.dir/rule
.PHONY : save-load-state

# clean rule for target.
llama.cpp/examples/save-load-state/CMakeFiles/save-load-state.dir/clean:
	$(MAKE) $(MAKESILENT) -f llama.cpp\examples\save-load-state\CMakeFiles\save-load-state.dir\build.make llama.cpp/examples/save-load-state/CMakeFiles/save-load-state.dir/clean
.PHONY : llama.cpp/examples/save-load-state/CMakeFiles/save-load-state.dir/clean

#=============================================================================
# Target rules for target llama.cpp/pocs/vdot/CMakeFiles/vdot.dir

# All Build rule for target.
llama.cpp/pocs/vdot/CMakeFiles/vdot.dir/all: llama.cpp/CMakeFiles/llama.dir/all
llama.cpp/pocs/vdot/CMakeFiles/vdot.dir/all: llama.cpp/examples/CMakeFiles/common.dir/all
	$(MAKE) $(MAKESILENT) -f llama.cpp\pocs\vdot\CMakeFiles\vdot.dir\build.make llama.cpp/pocs/vdot/CMakeFiles/vdot.dir/depend
	$(MAKE) $(MAKESILENT) -f llama.cpp\pocs\vdot\CMakeFiles\vdot.dir\build.make llama.cpp/pocs/vdot/CMakeFiles/vdot.dir/build
	@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --progress-dir="E:\Python Projects\R.O.B.E.R.T\source\R.O.B.E.R.T\src\training\gpt4all\gpt4all-backend\build\CMakeFiles" --progress-num=26,27 "Built target vdot"
.PHONY : llama.cpp/pocs/vdot/CMakeFiles/vdot.dir/all

# Build rule for subdir invocation for target.
llama.cpp/pocs/vdot/CMakeFiles/vdot.dir/rule: cmake_check_build_system
	$(CMAKE_COMMAND) -E cmake_progress_start "E:\Python Projects\R.O.B.E.R.T\source\R.O.B.E.R.T\src\training\gpt4all\gpt4all-backend\build\CMakeFiles" 6
	$(MAKE) $(MAKESILENT) -f CMakeFiles\Makefile2 llama.cpp/pocs/vdot/CMakeFiles/vdot.dir/all
	$(CMAKE_COMMAND) -E cmake_progress_start "E:\Python Projects\R.O.B.E.R.T\source\R.O.B.E.R.T\src\training\gpt4all\gpt4all-backend\build\CMakeFiles" 0
.PHONY : llama.cpp/pocs/vdot/CMakeFiles/vdot.dir/rule

# Convenience name for target.
vdot: llama.cpp/pocs/vdot/CMakeFiles/vdot.dir/rule
.PHONY : vdot

# clean rule for target.
llama.cpp/pocs/vdot/CMakeFiles/vdot.dir/clean:
	$(MAKE) $(MAKESILENT) -f llama.cpp\pocs\vdot\CMakeFiles\vdot.dir\build.make llama.cpp/pocs/vdot/CMakeFiles/vdot.dir/clean
.PHONY : llama.cpp/pocs/vdot/CMakeFiles/vdot.dir/clean

#=============================================================================
# Target rules for target llama.cpp/pocs/vdot/CMakeFiles/q8dot.dir

# All Build rule for target.
llama.cpp/pocs/vdot/CMakeFiles/q8dot.dir/all: llama.cpp/CMakeFiles/llama.dir/all
llama.cpp/pocs/vdot/CMakeFiles/q8dot.dir/all: llama.cpp/examples/CMakeFiles/common.dir/all
	$(MAKE) $(MAKESILENT) -f llama.cpp\pocs\vdot\CMakeFiles\q8dot.dir\build.make llama.cpp/pocs/vdot/CMakeFiles/q8dot.dir/depend
	$(MAKE) $(MAKESILENT) -f llama.cpp\pocs\vdot\CMakeFiles\q8dot.dir\build.make llama.cpp/pocs/vdot/CMakeFiles/q8dot.dir/build
	@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --progress-dir="E:\Python Projects\R.O.B.E.R.T\source\R.O.B.E.R.T\src\training\gpt4all\gpt4all-backend\build\CMakeFiles" --progress-num=18,19 "Built target q8dot"
.PHONY : llama.cpp/pocs/vdot/CMakeFiles/q8dot.dir/all

# Build rule for subdir invocation for target.
llama.cpp/pocs/vdot/CMakeFiles/q8dot.dir/rule: cmake_check_build_system
	$(CMAKE_COMMAND) -E cmake_progress_start "E:\Python Projects\R.O.B.E.R.T\source\R.O.B.E.R.T\src\training\gpt4all\gpt4all-backend\build\CMakeFiles" 6
	$(MAKE) $(MAKESILENT) -f CMakeFiles\Makefile2 llama.cpp/pocs/vdot/CMakeFiles/q8dot.dir/all
	$(CMAKE_COMMAND) -E cmake_progress_start "E:\Python Projects\R.O.B.E.R.T\source\R.O.B.E.R.T\src\training\gpt4all\gpt4all-backend\build\CMakeFiles" 0
.PHONY : llama.cpp/pocs/vdot/CMakeFiles/q8dot.dir/rule

# Convenience name for target.
q8dot: llama.cpp/pocs/vdot/CMakeFiles/q8dot.dir/rule
.PHONY : q8dot

# clean rule for target.
llama.cpp/pocs/vdot/CMakeFiles/q8dot.dir/clean:
	$(MAKE) $(MAKESILENT) -f llama.cpp\pocs\vdot\CMakeFiles\q8dot.dir\build.make llama.cpp/pocs/vdot/CMakeFiles/q8dot.dir/clean
.PHONY : llama.cpp/pocs/vdot/CMakeFiles/q8dot.dir/clean

#=============================================================================
# Special targets to cleanup operation of make.

# Special rule to run CMake to check the build system integrity.
# No rule that depends on this can have commands that come from listfiles
# because they might be regenerated.
cmake_check_build_system:
	$(CMAKE_COMMAND) -S$(CMAKE_SOURCE_DIR) -B$(CMAKE_BINARY_DIR) --check-build-system CMakeFiles\Makefile.cmake 0
.PHONY : cmake_check_build_system

